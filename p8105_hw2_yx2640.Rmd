---
title: "p8105_hw2_yx2640"
author: "Elaine Xu"
date: "9/30/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

# Problem 1

First, define a path to the dataset. 

```{r}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read the Mr. Trashwheel dataset. 

```{r}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
	)
```

Read precipitation data for 2018 and 2017. 

```{r}
precip_2018 = 
	read_excel(
		path = path_to_data,
		sheet = "2018 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2018) %>% 
	relocate(year)

precip_2017 = 
	read_excel(
		path = path_to_data,
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2017) %>% 
	relocate(year)
```

Now combine annual precipitation dataframes.

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)

precip_df = 
	bind_rows(precip_2018, precip_2017)

precip_df =
	left_join(precip_df, month_df, by = "month")
```

##### The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in the final dataset after omit non-data entries. Additional data sheets include month precipitation data. In this dataset:

##### * The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
##### * The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.


# Problem 2

Read the NYC transit dataset.

```{r}
NYC_df = 
	read_csv(
		"./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
		)%>%
  janitor::clean_names()%>%
  select(c(2:18, 20, 23))%>%
  mutate(entry = as.logical(recode(entry, "YES" = 'TRUE', "NO" = 'FALSE')))

names(NYC_df)
#skimr::skim(NYC_df)
```

##### * This dataset focuses on NYC transit data that contains the entrances and exits data for different subway stations. The dataset was originally include `r ncol(read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",))` columns of data. We pulled out columns includes the line and station name, station latitude and longitude, routes served, entry and entrance type, vending and ADA to create a new dataset for analysis. The resulting dataset has `r ncol(NYC_df)` columns and `r nrow(NYC_df)` rows. 

##### * After import the data, using clean_names() function to clean the variable names. By pulling out 19 columns from the original data, we recreate a data set that is smaller, which can help us focusing on the data we need. We also change the varible typr in the "entry" column from character variable (YES/NO) to logical variable (TRUE/FALSE).

##### * The data was not very tidy by looking at the columns through "route1" to "route11". There are many empty spacies that was expressing the same thing.

Find distinct stations, stations with ADA compliant, proportion of station entrances/ exits without vending allow entrance.

```{r}
#Distinct Stations
dis_line_stat = distinct(NYC_df, line, station_name, .keep_all = TRUE)

#Stations with ADA compliant
Station_ADA = sum(pull(dis_line_stat, ada), na.rm = TRUE)

#Proportion
proportion = nrow(filter(NYC_df, vending == "NO", entry == "TRUE"))/nrow(filter(NYC_df, vending == "NO"))
```
##### There are `r nrow(dis_line_stat)` dustunct stations. 84 of the stations are ADA compliant. The proportion of station entrances/ exits without vending allow entrance is `r proportion*100`%.


```{r}
#Reformat data so that route number and route name are distinct variables
Route_line = NYC_df %>%
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11))%>%
  pivot_longer(route1:route11, names_to = "route_number", values_to = "route_name")

Route_line = distinct(Route_line, station_name, line, .keep_all = TRUE)

#Distinct stations serve the A train 
Station_A = filter(Route_line, route_name == "A")

#Stations serve the A train and ADA compliant
Station_A_ADA = filter(Route_line, route_name == "A", ada == "A")
```

##### There are `r nrow(Station_A)` distinct stations serve the A train. `r nrow(Station_A_ADA)` of the stations that serve the A train are ADA compliant.


# Problem 3
 
First, clean the data in pols-month
```{r}
# separate mon, replace month number with month name
pols_month = 
	read_csv(
		"./data/fivethirtyeight_datasets/pols-month.csv"
		) %>%
  janitor::clean_names() %>%
  separate(mon, c("year","month","day")) %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day))%>%
  mutate(month = month.abb[month])

# create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable
pols_month = mutate(pols_month, president = ifelse(prez_gop == "0", "dem","gop"))%>%
  relocate(president, .before = "gov_gop")%>%
  select(-c(3,4,8))
```

Second, clean the data in snp.csv
```{r}
# separate date, replace month number with month name, arrange by year and month
snp = 
	read_csv(
		"./data/fivethirtyeight_datasets/snp.csv"
		) %>%
  janitor::clean_names() %>%
  separate(date, c("month","day","year")) %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day))%>%
  arrange(year, month)%>%
  mutate(month = month.abb[month])%>%
  relocate(year, .before = "month")

```

Third, tidy the unemployment data 
```{r}
unemploy = 
	read_csv(
		"./data/fivethirtyeight_datasets/unemployment.csv"
		)%>%
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemploy_percent")%>%
  mutate(Year = as.integer(Year))
  
```

Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}

```
















